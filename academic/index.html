<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Page Title -->
    <title>Academic &mdash; aria42</title>
    
      <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,500,600,700|Roboto:400,500,600,700" rel="stylesheet" type="text/css">
    
    <meta name="title" content="Academic ">
    <!--  Style -->
    <link rel="stylesheet" type="text/css" href="/css/main.css">
    <!-- <link rel="javascript" type="text/javascript" href="/js/main.js"> -->
    <!--  Icon -->
    <link rel="shortcut icon" href="/images/favicon.png" type="image/png" />
    <link rel="apple-touch-icon" href="/images/favicon-ios.png"/>
    <!--  RSS -->
    <link href="/feed.xml" rel="alternate" type="application/rss+xml" title="aria42" />
    <!--  Canonical -->
    <link rel="canonical" href="http://aria42.com/academic/">
    <!--  Facebook OG -->
    <meta property="og:title" content="Academic "/>
    <meta property="og:url" content="http://aria42.com/academic/"/>
    
    
    <meta property="og:site_name" content="aria42">

    <!-- MathTex -->
    

    <!-- Icon book -->
    <link href="/webfonts/ss-social-circle.css" rel="stylesheet" />
</head>
<body>

<section class="site-nav">
    <header>
        <nav id="navigation">
            <ul id="navigation-menu">
                <li>
                  <a class="logo nav-button-home" href="/">
                    <?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg width="172px" height="173px" viewBox="0 0 172 173" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:sketch="http://www.bohemiancoding.com/sketch/ns">
    <!-- Generator: Sketch 3.1.1 (8761) - http://www.bohemiancoding.com/sketch -->
    <title>logo</title>
    <desc>Created with Sketch.</desc>
    <defs></defs>
    <g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd" sketch:type="MSPage">
        <g id="logo" sketch:type="MSLayerGroup" transform="translate(-12.000000, -9.659028)">
            <ellipse id="Oval-1" fill="#444444" sketch:type="MSShapeGroup" cx="97.9918197" cy="96.5029479" rx="85.9918197" ry="86.0129479"></ellipse>
            <text id="42" sketch:type="MSTextLayer" font-family="Plantagenet Cherokee" font-size="179" font-weight="normal" sketch:alignment="middle" fill="#FFFFFF">
                <tspan x="17.777" y="125">42</tspan>
            </text>
        </g>
    </g>
</svg>
                  </a>
                </li>
            
                <li>
                  <a class="nav-text-button nav-button-blog" href="/blog">
                      BLOG
                  </a>
                </li>
            
                <li>
                  <a class="nav-text-button nav-button-academic" href="/academic">
                      ACADEMIC
                  </a>
                </li>
            
                <li>
                  <a class="nav-text-button nav-button-media" href="/media">
                      MEDIA
                  </a>
                </li>
            
            </ul>
        </nav>
    </header>
</section>

<article class="container">
    <!-- <section class="title"><h1>Academic Papers</h1></section> -->

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of ACL 2011</span>
            </div>
						
            <h2 class="title"><a href="http://people.csail.mit.edu/regina/my_papers/twitter_acl2011.pdf"> Event Discovery in Social Media Feeds</a></h2>
            <div class="authors paper-section">
						  Edward Benson, Me, and Regina Barzilay
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="http://people.csail.mit.edu/regina/my_papers/twitter_acl2011.pdf">PDF</a></li>
                
								
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								We present a novel method for record extrac- tion from social streams such as Twitter. Un- like typical extraction setups, these environ- ments are characterized by short, one sentence messages with heavily colloquial speech. To further complicate matters, individual mes- sages may not express the full relation to be uncovered, as is often assumed in extraction tasks. We develop a graphical model that ad- dresses these problems by learning a latent set of records and a record-message alignment si- multaneously; the output of our model is a set of canonical records, the values of which are consistent with aligned messages. We demonstrate that our approach is able to accu- rately induce event records from Twitter mes- sages, evaluated against events from a local city guide. Our method achieves significant error reduction over baseline methods
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of ACL 2011</span>
            </div>
						
            <h2 class="title"><a href="http://people.csail.mit.edu/regina/my_papers/content_acl2011.pdf"> Content Models with Attitude</a></h2>
            <div class="authors paper-section">
						  Christina Sauper, Me, and Regina Barzilay
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="http://people.csail.mit.edu/regina/my_papers/content_acl2011.pdf">PDF</a></li>
                
								
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								We present a probabilistic topic model for jointly identifying properties and attributes of social media review snippets. Our model simultaneously learns a set of properties of a product and captures aggregate user senti- ments towards these properties. This approach directly enables discovery of highly rated or inconsistent properties of a product. Our model admits an efficient variational mean- field inference algorithm which can be paral- lelized and run on large snippet collections. We evaluate our model on a large corpus of snippets from Yelp reviews to assess property and attribute prediction. We demonstrate that it outperforms applicable baselines by a con- siderable margin.
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of CoNLL 2011</span>
            </div>
						
            <h2 class="title"><a href="http://people.csail.mit.edu/regina/my_papers/morph_conll2011.pdf"> Modeling Syntactic Context Improves Morphological Segmentation</a></h2>
            <div class="authors paper-section">
						  Yeong Keok Lee, Me, and Regina Barzilay
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="http://people.csail.mit.edu/regina/my_papers/morph_conll2011.pdf">PDF</a></li>
                
								
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								The connection between part-of-speech (POS) categories and morphological properties is well-documented in linguistics but underuti- lized in text processing systems. This pa- per proposes a novel model for morphologi- cal segmentation that is driven by this connec- tion. Our model learns that words with com- mon affixes are likely to be in the same syn- tactic category and uses learned syntactic cat- egories to refine the segmentation boundaries of words. Our results demonstrate that incor- porating POS categorization yields substantial performance gains on morphological segmen- tation of Arabic.
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of EMNLP 2010</span>
            </div>
						
            <h2 class="title"><a href="/pubs/sauper-emnlp10.pdf"> Incorporating Content Structure into Text Analysis Applications</a></h2>
            <div class="authors paper-section">
						  Christina Sauper, Me, and Regina Barzilay
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/sauper-emnlp10.pdf">PDF</a></li>
                
								
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of EMNLP 2010</span>
            </div>
						
            <h2 class="title"><a href="/pubs/typetagging.pdf"> Simple Type-Level Unsupervised POS Tagging</a></h2>
            <div class="authors paper-section">
						  Yeong Keok Lee, Me, and Regina Barzilay
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/typetagging.pdf">PDF</a></li>
                
								
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								Part-of-speech (POS) tag distributions are known to exhibit sparsity --- a word is likely to take a single predominant tag in a corpus. Recent research has demonstrated that incorporating this sparsity constraint improves tagging accuracy. However, in existing systems, this expansion come with a steep increase in model complexity. This paper proposes a simple and effective tagging method that directly models tag sparsity and other distributional properties of valid POS tag assignments. In addition, this formulation results in a dramatic reduction in the number of model parameters thereby, enabling unusually rapid training. Our experiments consistently demonstrate that this model architecture yields substantial performance gains over more complex tagging counterparts. On several languages, we report performance exceeding that of more complex state-of-the art systems.
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of ACL 2010</span>
            </div>
						
            <h2 class="title"><a href="/pubs/iecoref.pdf"> An Entity-Level Approach to Information Extraction</a></h2>
            <div class="authors paper-section">
						  Me and Dan Klein
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/iecoref.pdf">PDF</a></li>
                
								
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								We present a generative model of template-filling in which coreference resolution and role assignment are jointly determined. Underlying template roles first generate abstract entities, which in turn generate concrete textual mentions. On the standard corporate acquisitions dataset, joint resolution in our entity-level model reduces error over a mention-level discriminative approach by up to 20%.
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of NAACL 2010 [<b>BEST PAPER AWARD</b>]</span>
            </div>
						
            <h2 class="title"><a href="/pubs/naacl2010-coref2.pdf"> Coreference Resolution in a Modular, Entity-Centered Model</a></h2>
            <div class="authors paper-section">
						  Me and Dan Klein
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/naacl2010-coref2.pdf">PDF</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/naacl2010-coref2.pdf">SLIDES</a></li>
                
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								Coreference resolution is governed by syntactic, semantic, and discourse constraints. We present a generative, model-based approach in which each of these factors is modularly en- capsulated and learned in a primarily unsupervised manner. Our semantic representation first hypothesizes an underlying set of latent entity types, which generate specific entities that in turn render individual mentions. By sharing lexical statistics at the level of abstract entity types, our model is able to substantially reduce semantic compatibility errors, resulting in the best results to date on the complete end-to-end coreference task.
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of NAACL 2009</span>
            </div>
						
            <h2 class="title"><a href="/pubs/naacl09-topical.pdf"> Exploring Content Models for Multi-Document Summarization</a></h2>
            <div class="authors paper-section">
						  Me and Lucy Vanderwende
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/naacl09-topical.pdf">PDF</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/naacl09-topical.pdf">SLIDES</a></li>
                
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								We present an exploration of generative probabilistic models for multi-document summarization. Beginning with a simple word fre- quency based model (Nenkova and Vanderwende, 2005), we construct a sequence of models each injecting more structure into the representation of document set content and exhibiting ROUGE gains along the way. Our final model, HIERSUM, utilizes a hierarchical LDA-style model (Blei et al., 2004) to represent content specificity as a hierarchy of topic vocabulary distributions. At the task of producing generic DUC-style summaries, HIERSUM yields state-of-the-art ROUGE performance and in pairwise user evaluation strongly outperforms Toutanova et al. (2007)'s state-of-the-art discriminative system.	We also explore HIERSUM's capacity to produce multiple 'topical summaries' in order to facilitate content discovery and navigation.
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of ACL 2009</span>
            </div>
						
            <h2 class="title"><a href="/pubs/acl09-itg.pdf"> Better Word Alignments with Supervised ITG Models</a></h2>
            <div class="authors paper-section">
						  Me, John Blitzer, and and "Dan Klein"
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/acl09-itg.pdf">PDF</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/acl09-itg.pdf">SLIDES</a></li>
                
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								This work investigates supervised word alignment methods that exploit inversion transduction grammar (ITG) constraints. We consider maximum margin and conditional likelihood objectives, including the presentation of a new normal form grammar for canonicalizing derivations. Even for non-ITG sentence pairs, we show that it is possible learn ITG alignment models by simple relaxations of structured discriminative learning objectives. For efficiency, we describe a set of pruning techniques that together allow us to align sentences two orders of magnitude faster than naive bitext CKY parsing. Finally, we introduce many-to-one block alignment features, which significantly improve our ITG models. Altogether, our method results in the best reported AER numbers for Chinese-English and a performance improvement of 1.1 BLEU over GIZA++ alignments.
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of EMNLP 2009</span>
            </div>
						
            <h2 class="title"><a href="http://aclweb.org/anthology-new/D/D09/D09-1120.pdf"> Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></h2>
            <div class="authors paper-section">
						  Me and Dan Klein
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="http://aclweb.org/anthology-new/D/D09/D09-1120.pdf">PDF</a></li>
                
								
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								Coreference systems are driven by syntactic, semantic, and discourse constraints. We present a simple approach which completely modularizes these three aspects. In contrast to much current work, which focuses on learning and on the discourse component, our system is deterministic and is driven entirely by syntactic and semantic compatibility as learned from a large, unlabeled corpus. Despite its simplicity and discourse naivete, our system substantially outperforms all unsupervised systems and most supervised ones. Primary contributions include (1) the presentation of a simple- to-reproduce, high-performing baseline and (2) the demonstration that most remaining errors can be attributed to syntactic and semantic factors external to the coreference phenomenon (and perhaps best addressed by non-coreference systems).
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of ACL 2008</span>
            </div>
						
            <h2 class="title"><a href="/pubs/acl2008-unsup-bilexicon.pdf"> Learning Bilingual Lexicons from Monolingual Corpora</a></h2>
            <div class="authors paper-section">
						  Me, Percy Liang, Taylor Berg-Kirkpatrick, and Dan Klein
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/acl2008-unsup-bilexicon.pdf">PDF</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/acl2008-unsup-bilexicon.pdf">SLIDES</a></li>
                
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								We present a method for learning bilingual translation lexicons from monolingual corpora. Word types in each language are characterized by purely monolingual features, such as context counts and orthographic substrings. Translations are induced using a generative model based on canonical correlation analysis, which explains the monolingual lexicons in terms of latent matchings. We show that high-precision lexicons can be learned in a variety of language pairs and from a range of corpus types.
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of EMNLP 2008</span>
            </div>
						
            <h2 class="title"><a href="/pubs/emnlp08b.pdf"> Coarse-to-Fine Syntactic Machine Translation using Language Projections</a></h2>
            <div class="authors paper-section">
						  Slav Petrov, Me, and Dan Klein
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/emnlp08b.pdf">PDF</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/emnlp08b.pdf">SLIDES</a></li>
                
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								The intersection of tree transducer-based translation models with n-gram language models results in huge dynamic programs for machine translation decoding.  We propose a multipass, coarse-to-fine approach in which the language model complexity is incrementally introduced.  In contrast to previous *order-based* bigram-to-trigram approaches, we focus on *encoding-based* methods, which use a clustered encoding of the target language.  Across various hierarchical encoding schemes and for multiple language pairs, we show speed-ups of up to 50 times over single-pass decoding while improving BLEU score.  Moreover, our entire decoding cascade for trigram language models is faster than the corresponding bigram pass alone of a bigram-to-trigram decoder.
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <h2 class="title"><a href="http://w01fe.com/berkeley/pubs/08-icml-em.pdf"> Fully Distributed EM for Very Large Datasets</a></h2>
            <div class="authors paper-section">
						  Jason Wolfe, Me, and Dan Klein
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="http://w01fe.com/berkeley/pubs/08-icml-em.pdf">PDF</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="http://w01fe.com/berkeley/pubs/08-icml-em.pdf">SLIDES</a></li>
                
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								In EM and related algorithms, E-step computations distribute easily, because data items are independent given parameters. For very large data sets, however, even storing all of the parameters in a single node for the M- step can be impractical. We present a framework that fully distributes the entire EM procedure. Each node interacts only with parameters relevant to its data, sending messages to other nodes along a junction-tree topology. We demonstrate improvements over a MapReduce topology, on two tasks: word alignment and topic modeling.
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of Computational Linguistics</span>
            </div>
						
            <h2 class="title"><a href="http://aclweb.org/anthology-new/J/J08/J08-2002.pdf"> A Global Joint Model for Semantic Role Labeling</a></h2>
            <div class="authors paper-section">
						  Kristina Toutanova, Me, and Christopher D. Manning
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
								
                  <li style="float:left;"><a target="_blank" href="http://aclweb.org/anthology-new/J/J08/J08-2002.pdf">PDF</a></li>
                
								
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of ACL 2007</span>
            </div>
						
            <h2 class="title"><a href="/pubs/acl07-hdp-coref.pdf"> Unsupervised Coreference Resolution in a Nonparametric Bayesian Model</a></h2>
            <div class="authors paper-section">
						  Me and Dan Klein
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/acl07-hdp-coref.pdf">PDF</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/acl07-hdp-coref.pdf">SLIDES</a></li>
                
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								We present an unsupervised, nonparametric Bayesian approach to coreference resolution which models both global entity identity across a corpus as well as the sequential anaphoric structure within each document. While most existing coreference work is driven by pairwise decisions, our model is fully generative, producing each mention from a combination of global entity proper- ties and local attentional state. Despite be- ing unsupervised, our system achieves a 70.3 MUC F1 measure on the MUC-6 test set, broadly in the range of some recent supervised results.
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of NAACL 2007</span>
            </div>
						
            <h2 class="title"><a href="/pubs/factor-astar-naacl07.pdf"> Approximate Factoring for A* Search</a></h2>
            <div class="authors paper-section">
						  Me, John DeNero, and Dan Klein
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/factor-astar-naacl07.pdf">PDF</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/factor-astar-naacl07.pdf">SLIDES</a></li>
                
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								We present a novel method for creating A∗ estimates for structured search problems. In our approach, we project a complex model onto multiple simpler models for which exact inference is efficient. We use an optimization framework to estimate parameters for these projections in a way which bounds the true costs. Similar to Klein and Manning (2003), we then combine completion estimates from the simpler models to guide search in the original complex model. We apply our approach to bitext parsing and lexicalized parsing, demonstrating its effectiveness in these domains.
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of AAAI 2007</span>
            </div>
						
            <h2 class="title"><a href=""> A* Search via Approximate Factoring</a></h2>
            <div class="authors paper-section">
						  Me, John DeNero, and Dan Klein
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
								
								
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of NAACL 2006</span>
            </div>
						
            <h2 class="title"><a href="/pubs/naacl06-posinduction.pdf"> Prototype-driven Learning for Sequence Models</a></h2>
            <div class="authors paper-section">
						  Me and Dan Klein
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/naacl06-posinduction.pdf">PDF</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/naacl06-posinduction.pdf">SLIDES</a></li>
                
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								We investigate prototype-driven learning for primarily unsupervised sequence modeling. Prior knowledge is specified declaratively, by providing a few canonical examples of each target an- notation label. This sparse prototype information is then propagated across a corpus using distributional similarity features in a log-linear generative model. On part-of-speech induction in English and Chinese, as well as an information extraction task, prototype features provide substantial error rate reductions over competitive baselines and outperform previous work. For example, we can achieve an English part-of-speech tagging accuracy of 80.5% using only three examples of each tag and no dictionary constraints. We also compare to semi-supervised learning and discuss the system's error trends.
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of ACL 2006</span>
            </div>
						
            <h2 class="title"><a href="/pubs/acl06-grammarinduction.pdf"> Prototype-driven Grammar Induction</a></h2>
            <div class="authors paper-section">
						  Me and Dan Klein
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
                  <li style="float:left;"><a onclick="javascript:toggleAbstract(this)">ABSTRACT</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/acl06-grammarinduction.pdf">PDF</a></li>
                
								
                  <li style="float:left;"><a target="_blank" href="/pubs/acl06-grammarinduction.pdf">SLIDES</a></li>
                
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								We investigate prototype-driven learning for primarily unsupervised grammar induction. Prior knowledge is specified declaratively, by providing a few canonical examples of each target phrase type. This sparse prototype information is then propagated across a corpus using distributional similarity features, which augment an otherwise standard PCFG model. We show that distributional features are effective at distinguishing bracket labels, but not determining bracket locations. To improve the quality of the induced trees, we combine our PCFG induction with the CCM model of Klein and Manning (2002), which has complementary strengths: it identifies brackets but does not label them. Using only a handful of prototypes, we show substantial improvements over naive PCFG induction for English and Chinese grammar induction.
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <h2 class="title"><a href="/pubs/rte-emnlp05.pdf"> Robust Textual Inference via Graph Matching</a></h2>
            <div class="authors paper-section">
						  Aria D. Haghighi, Andrew Y. Ng, and Christopher D. Manning
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
								
                  <li style="float:left;"><a target="_blank" href="/pubs/rte-emnlp05.pdf">PDF</a></li>
                
								
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of PASCAL Challenge Workshop in Recognizing Textual Entailment 2005</span>
            </div>
						
            <h2 class="title"><a href="/pubs/rte.pdf"> Robust Textual Inference Using Diverse Knowledge Sources</a></h2>
            <div class="authors paper-section">
						  Rajat Raina, Me, Christopher Cox, Jenny Finkel, Jeff Michels, Kristina Toutanova, Bill MacCartney, Marie-Catherine de Marneffe, Christopher D. Manning, and Andrew Y. Ng
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
								
                  <li style="float:left;"><a target="_blank" href="/pubs/rte.pdf">PDF</a></li>
                
								
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <h2 class="title"><a href="http://www-nlp.stanford.edu/~manning/papers/conll2005new.pdf"> A Joint Model for Semantic Role Labeling</a></h2>
            <div class="authors paper-section">
						  Kristina Toutanova, Aria Hahgighi, and Chris D. Manning
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
								
                  <li style="float:left;"><a target="_blank" href="http://www-nlp.stanford.edu/~manning/papers/conll2005new.pdf">PDF</a></li>
                
								
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

    <section class="index">
        <!-- -->
        <div class="academic-paper">
            
            <div class="meta">
              <span> Proceedings of ACL 2005</span>
            </div>
						
            <h2 class="title"><a href="/pubs/srljoint.pdf"> Joint Learning Improves Semantic Role Labeling</a></h2>
            <div class="authors paper-section">
						  Kristina Toutanova, Aria Hahgighi, and Chris D. Manning
            </div>

						<div class="toggler paper-section">
							<ul class="paper-present">
								
								
                  <li style="float:left;"><a target="_blank" href="/pubs/srljoint.pdf">PDF</a></li>
                
								
                <li style="clear:both;"></li>
							</ul>
						</div>
						<div class="abstract">
              <blockquote>
								
              </blockquote>
						</div>
        </div>
        <hr>
    </section>

</article>


<footer class="site-footer">
        <div class="contact">
            <a href="http://twitter.com/aria42" class="home"><i class="ss-icon">twitter</i></a>
            <a href="http://github.com/aria42" class="home"><i class="ss-icon">octocat</i></a>
            <a href="http://linkedin.com/in/aria42" class="home"><i class="ss-icon">linkedin</i></a>
            <a href="mailto:me@aria42.com" class="home" style="margin-right:0em"><i class="ss-icon">email</i></a>
        </div>
        <div class="blah">
        &copy; 2016 <a href="http://aria42.com/">aria42.com</a>
        </div>
</footer>

<script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>





<script src="/webfonts/ss-social.js"></script>
<script>
  function toggleAbstract(elem) {
      $(elem).parents(".academic-paper").find(".abstract").toggle();
  }

  $(".full img").on("click", function() {
  $(this).toggleClass("zoom");
});

SVGElement.prototype.addClass = function (className) {
  if (!this.hasClass(className)) {
    this.setAttribute('class', this.getAttribute('class') + ' ' + className);
  }
};

$("a.nav-text-button").on({ 'touchstart' : function(){
  $(this).addClass('active');
}});

$("a.nav-text-button").on({ 'touchend' : function(){
  $(this).removeClass('active');
}});
$("a.nav-text-button").on({ 'touchleave' : function(){
  $(this).removeClass('active');
}});

function svgFill() {
  $('img[src$="svg"]').hide()
    .each(function(i, item) {
      var _this = this;
      return $.get(this.src).success(function(data) {
        var $svg, a, nName, nValue, _attr, _i, _len;
        $svg = $(data).find('svg');
        _attr = _this.attributes;
        $.extend(_attr, $svg[0].attributes);
        for (_i = 0, _len = _attr.length; _i < _len; _i++) {
          a = _attr[_i];
          nName = a.nodeName;
          nValue = a.nodeValue;
          if (nName !== 'src' && nName !== 'style') {
            $svg.attr(nName, nValue);
          }
        }
        return $(_this).replaceWith($svg);
      });
  });
}

var accented = "#428bca";

function setupHeader() {
  var uri = window.location.pathname.substring(1);
  if (uri.indexOf("/") >= 0) {
    uri = uri.substring(0, uri.indexOf("/"));
  }
  if (uri == "") {
    var loop = setInterval(function() {
      if ($(".nav-button-home svg ellipse").length) {
        $(".nav-button-home svg ellipse").attr("fill",accented);
      }
    }, 5)
  } else {
    $(".nav-button-" + uri).addClass("accented");
  }
}

(function() {
  $(svgFill);
  $(setupHeader);
}).call(this);


</script>

  <!--google analytics tracking code here-->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-57015155-1', 'auto');
  ga('send', 'pageview');

</script>
<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=5151559;
var sc_invisible=1;
var sc_security="c3abe7d5";
</script>
<script type="text/javascript"
src="http://www.statcounter.com/counter/counter.js"></script>
<!-- End of StatCounter Code for Default Guide -->




</body>
</html>
